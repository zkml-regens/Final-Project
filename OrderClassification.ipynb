{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32570,"status":"ok","timestamp":1742883593164,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"fw2hGDG3254l","outputId":"cbaef2fd-9c32-45ca-f23d-ccc6699c17b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["try:\n","    # install ezkl\n","    import google.colab\n","    import subprocess\n","    import sys\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n","\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","\n","# rely on local installation of ezkl if the notebook is not in colab\n","except:\n","    pass"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":374,"status":"ok","timestamp":1742883597029,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"2gnZF-Tb7SS8"},"outputs":[],"source":["import os\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111,"status":"ok","timestamp":1742883599361,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"ZHw9aOuE7tv9","outputId":"ded7de78-44b4-453a-d591-f2ef072515d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["gdrive\tsample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1742883601776,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"M9PwXAco85yX"},"outputs":[],"source":["imageDir = \"/content/gdrive/MyDrive/ZKML Regens/ml_ready_plants\"\n","train_annotations_file = \"/content/gdrive/MyDrive/ZKML Regens/ml_ready_plants_metadata/train_imagesOrders.tsv\"\n","test_annotations_file = \"/content/gdrive/MyDrive/ZKML Regens/ml_ready_plants_metadata/test_imagesOrders.tsv\""]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1742884040995,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"My-ZUUIl-V5c"},"outputs":[],"source":["import os\n","import pandas as pd\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import unicodedata\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","        self.img_labels = pd.read_csv(annotations_file, encoding='utf8', sep = \"\\t\")\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        img_path = unicodedata.normalize('NFC', img_path)\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1742884047929,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"Xog0ed8X3bwR"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 32)\n","        self.fc2 = nn.Linear(32, 7)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1742884050694,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"UHgK6ZuSg3pY"},"outputs":[],"source":["# Running out of RAM. Change to 1 channel.\n","transform = transforms.Compose(\n","        [\n","            transforms.Resize((33, 33)),\n","            transforms.RandomCrop((32, 32))\n","        ]\n","    )"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1742884053444,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"-ZhWjgaAiQgh"},"outputs":[],"source":["train_dataset = CustomImageDataset(train_annotations_file, imageDir, transform=transform)\n","\n","# ???\n","test_dataset = CustomImageDataset(test_annotations_file, imageDir, transform=transform)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1742884058680,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"slqGD6J_08r2","outputId":"b0fef5cf-59da-4da0-fee2-102ec2e14273"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 6, 28, 28]             456\n","         MaxPool2d-2            [-1, 6, 14, 14]               0\n","            Conv2d-3           [-1, 16, 10, 10]           2,416\n","         MaxPool2d-4             [-1, 16, 5, 5]               0\n","            Linear-5                   [-1, 32]          12,832\n","            Linear-6                    [-1, 7]             231\n","================================================================\n","Total params: 15,935\n","Trainable params: 15,935\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.06\n","Params size (MB): 0.06\n","Estimated Total Size (MB): 0.13\n","----------------------------------------------------------------\n"]}],"source":["from torch.utils.data import DataLoader\n","from torch.nn import CrossEntropyLoss\n","from torch.optim import Adam  # Import Adam\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import ToTensor\n","from torchsummary import summary\n","import numpy as np\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)\n","\n","model = CNN().to(device)\n","summary(model, (3, 32, 32))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-abOC5FXjXY7","executionInfo":{"status":"ok","timestamp":1742888509412,"user_tz":0,"elapsed":4443413,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}},"outputId":"5a47f00b-de85-4558-e239-462ed8744aab"},"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy: 0.250\n","test accuracy: 0.258\n","test accuracy: 0.273\n","test accuracy: 0.336\n","test accuracy: 0.344\n","test accuracy: 0.328\n","test accuracy: 0.367\n","test accuracy: 0.352\n","test accuracy: 0.391\n","test accuracy: 0.328\n","test accuracy: 0.391\n","test accuracy: 0.398\n","test accuracy: 0.398\n","test accuracy: 0.414\n","test accuracy: 0.414\n","test accuracy: 0.398\n","test accuracy: 0.391\n","test accuracy: 0.398\n","test accuracy: 0.430\n","test accuracy: 0.398\n","test accuracy: 0.445\n","test accuracy: 0.359\n","test accuracy: 0.430\n","test accuracy: 0.391\n","test accuracy: 0.398\n"]}],"source":["adam = Adam(model.parameters())  # Using Adam with a learning rate of 1e-3\n","loss_fn = CrossEntropyLoss()\n","all_epoch = 25\n","prev_acc = 0\n","for current_epoch in range(all_epoch):\n","    model.train()\n","    for idx, (train_x, train_label) in enumerate(train_loader):\n","        train_x = train_x.to(device)\n","        # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n","        train_x = train_x.round()\n","        train_label = train_label.to(device)\n","        adam.zero_grad()  # Use adam optimizer\n","        predict_y = model(train_x.float())\n","        loss = loss_fn(predict_y, train_label.long())\n","        loss.backward()\n","        adam.step()  # Use adam optimizer\n","    all_correct_num = 0\n","    all_sample_num = 0\n","    model.eval()\n","\n","    for idx, (test_x, test_label) in enumerate(test_loader):\n","        test_x = test_x.to(device)\n","        # normalize the image to 0 or 1 to reflect the inputs from the drawing board\n","        test_x = test_x.round()\n","        test_label = test_label.to(device)\n","        predict_y = model(test_x.float()).detach()\n","        predict_y = torch.argmax(predict_y, dim=-1)\n","        current_correct_num = predict_y == test_label\n","        all_correct_num += np.sum(current_correct_num.to('cpu').numpy(), axis=-1)\n","        all_sample_num += current_correct_num.shape[0]\n","    acc = all_correct_num / all_sample_num\n","    print('test accuracy: {:.3f}'.format(acc), flush=True)\n","    if not os.path.isdir(\"models_zkml\"):\n","        os.mkdir(\"models_zkml\")\n","    torch.save(model, 'models_zkml/plants{:.3f}.pkl'.format(acc))\n","    prev_acc = acc"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"MlhBEGjzo_D_","executionInfo":{"status":"ok","timestamp":1742888701096,"user_tz":0,"elapsed":3,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}}},"outputs":[],"source":["import os\n","\n","model_path = os.path.join('network_cnn.onnx')\n","compiled_model_path = os.path.join('network.compiled')\n","pk_path = os.path.join('key.pk')\n","vk_path = os.path.join('key.vk')\n","settings_path = os.path.join('settings.json')\n","witness_path = os.path.join('witness.json')\n","data_path = os.path.join('input.json')"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1742888712475,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"Wa70ArdYpDrT","outputId":"a7a36db8-bb92-461d-b9b2-2d8028b97ecc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model exported to network_cnn.onnx and input data saved to input.json\n"]}],"source":["import torch\n","import json\n","\n","model.eval()  # Set the model to evaluation mode\n","\n","# Fetch a single data point from the train_dataset\n","# Ensure train_dataset is already loaded and accessible\n","train_data_point, _ = next(iter(train_dataset))\n","train_data_point = train_data_point.unsqueeze(0)  # Add a batch dimension\n","\n","# Verify the device (CPU or CUDA) and transfer the data point to the same device as the model\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","train_data_point = train_data_point.to(device)\n","\n","# Convert the data point to float32 before exporting\n","train_data_point = train_data_point.type(torch.float32) # This line is added\n","\n","# Export the model to ONNX format\n","torch.onnx.export(model, train_data_point, model_path, export_params=True, do_constant_folding=True, input_names=['input_0'], output_names=['output'])\n","\n","# Convert the tensor to numpy array and reshape it for JSON serialization\n","x = train_data_point.cpu().detach().numpy().reshape([-1]).tolist()\n","data = {'input_data': [x]}\n","with open('input.json', 'w') as f:\n","    json.dump(data, f)\n","\n","print(f\"Model exported to {model_path} and input data saved to input.json\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43060,"status":"ok","timestamp":1742888771863,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"2VS4w97duxsb","outputId":"d2e2034e-7469-4086-b5e3-03b03e38ae87"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:ezkl.graph.model:[tensor] decomposition error: integer -296890674 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","ERROR:ezkl.graph.model:[tensor] decomposition error: integer 355605816 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","ERROR:ezkl.graph.model:[tensor] decomposition error: integer -645375175 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","ERROR:ezkl.graph.model:[tensor] decomposition error: integer -644211911 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","ERROR:ezkl.graph.model:[tensor] decomposition error: integer -1290750351 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","ERROR:ezkl.graph.model:[tensor] decomposition error: integer 2853226945 is too large to be represented by base 16384 and n 2\n","ERROR:ezkl.execute:forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","WARNING:ezkl.execute:\n","\n"," <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n","\n","+---------------+---------------+------------+--------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n","| mean_error    | median_error  | max_error  | min_error    | mean_abs_error | median_abs_error | max_abs_error | min_abs_error  | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n","+---------------+---------------+------------+--------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n","| -0.0010376641 | -0.0027389526 | 0.01808405 | -0.029117584 | 0.0062739686   | 0.0027389526     | 0.029117584   | 0.000018119812 | 0.00007196489      | -0.0037545946      | 0.0060200715           |\n","+---------------+---------------+------------+--------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n","\n","\n"]}],"source":["import ezkl\n","\n","run_args = ezkl.PyRunArgs()\n","run_args.input_visibility = \"private\"\n","run_args.param_visibility = \"fixed\"\n","run_args.output_visibility = \"public\"\n","run_args.num_inner_cols = 2\n","run_args.variables = [(\"batch_size\", 1)]\n","\n","# Capture set of data points\n","num_data_points = 10\n","\n","# Fetch 30 data points from the train_dataset\n","data_points = []\n","for i, (data_point, _) in enumerate(train_dataset):\n","    if i >= num_data_points:\n","        break\n","    data_points.append(data_point)\n","\n","# Stack the data points to create a batch\n","train_data_batch = torch.stack(data_points)\n","\n","# Add a batch dimension if not already present\n","if train_data_batch.dim() == 3:\n","    train_data_batch = train_data_batch.unsqueeze(0)\n","\n","x = train_data_batch.cpu().detach().numpy().reshape([-1]).tolist()\n","\n","data = dict(input_data = [x])\n","\n","cal_path = os.path.join('calibration.json')\n","\n","# Serialize data into file:\n","json.dump( data, open(cal_path, 'w' ))\n","\n","!RUST_LOG=trace\n","# TODO: Dictionary outputs\n","res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n","assert res == True\n","\n","res = await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n","assert res == True"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1742888776128,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"},"user_tz":0},"id":"GS1vrmG7zRYx"},"outputs":[],"source":["res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n","assert res == True"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"-yWO5Y0u1xHa","executionInfo":{"status":"ok","timestamp":1742888786227,"user_tz":0,"elapsed":6888,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}}},"outputs":[],"source":["# srs path\n","res = await ezkl.get_srs(settings_path)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"yg0z5qXB11RH","executionInfo":{"status":"ok","timestamp":1742888793610,"user_tz":0,"elapsed":553,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}}},"outputs":[],"source":["# now generate the witness file\n","witness_path = \"witness.json\"\n","\n","res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n","assert os.path.isfile(witness_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t08cusvt184f"},"outputs":[],"source":["#res = ezkl.mock(witness_path, compiled_model_path)\n","#assert res == True"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"PJaBo-on2Ozx","executionInfo":{"status":"ok","timestamp":1742888946548,"user_tz":0,"elapsed":146257,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}}},"outputs":[],"source":["# HERE WE SETUP THE CIRCUIT PARAMS\n","# WE GOT KEYS\n","# WE GOT CIRCUIT PARAMETERS\n","# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n","\n","res = ezkl.setup(\n","        compiled_model_path,\n","        vk_path,\n","        pk_path,\n","    )\n","\n","assert res == True\n","assert os.path.isfile(vk_path)\n","assert os.path.isfile(pk_path)\n","assert os.path.isfile(settings_path)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"6Eu51Fl82Q0_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742889125895,"user_tz":0,"elapsed":66,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}},"outputId":"89b6a692-b2cf-4a47-abc9-37142eb32178"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'instances': [['7c02000000000000000000000000000000000000000000000000000000000000', '9be6ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '4fe4ffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', '30baffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', 'fadaffef93f5e1439170b97948e833285d588181b64550b829a031e1724e6430', 'c049000000000000000000000000000000000000000000000000000000000000', 'c823000000000000000000000000000000000000000000000000000000000000']], 'proof': '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', 'transcript_type': 'EVM'}\n"]}],"source":["# GENERATE A PROOF\n","\n","\n","proof_path = os.path.join('test.pf')\n","\n","res = ezkl.prove(\n","        witness_path,\n","        compiled_model_path,\n","        pk_path,\n","        proof_path,\n","        \"single\",\n","    )\n","\n","print(res)\n","assert os.path.isfile(proof_path)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"SQor8WIU2Zgw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742889150832,"user_tz":0,"elapsed":14,"user":{"displayName":"Audrey Ekuban","userId":"02915065325760813979"}},"outputId":"f30c7177-c154-4666-8428-519edf37354f"},"outputs":[{"output_type":"stream","name":"stdout","text":["verified\n"]}],"source":["# VERIFY IT\n","res = ezkl.verify(\n","        proof_path,\n","        settings_path,\n","        vk_path,\n","    )\n","\n","assert res == True\n","print(\"verified\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}